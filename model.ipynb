{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 13)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast #for strings\n",
    "import re #regex\n",
    "\n",
    "fname='MSCI446_ Data - Sheet1.csv'\n",
    "\n",
    "def convert_to_numpy_array(string: str):\n",
    "    # Verify string is written like a python list\n",
    "    stripped = string.strip()\n",
    "    pattern = r\"\\[(.*)\\]\"\n",
    "    match = re.match(pattern, stripped)\n",
    "    if not match:\n",
    "        raise NotImplementedError(f\"{stripped}\")\n",
    "    # Group 1 captures the content inside the square brackets\n",
    "    contents = match.group(1)\n",
    "    \n",
    "    try:\n",
    "        # Use ast.literal_eval to safely evaluate string literals\n",
    "        evaluated = ast.literal_eval(stripped)\n",
    "        if type(evaluated) is not list:\n",
    "            raise NotImplementedError()\n",
    "        # series = pd.Series(evaluated)\n",
    "        return np.array(evaluated)\n",
    "    except (SyntaxError, ValueError):  # this occurs with the \"Condition\" column\n",
    "        # If parsing as a list fails, split the contents within the square brackets by comma, \n",
    "        # interpret each value as a string and strip whitespace\n",
    "        return np.array([ item.strip() for item in contents.split(',') ])\n",
    "\n",
    "# Read CSV file with the custom function\n",
    "numerical_vector_column_labels = ['Temperature (F)', 'Dewpoint (F)', 'Humidity (%)', 'Wind Speed (mph)', 'Pressure (in)', 'Percipitation (in)']\n",
    "categorical_vector_column_labels = [\"Condition\"]\n",
    "vector_column_labels = numerical_vector_column_labels + categorical_vector_column_labels\n",
    "\n",
    "# Create a converters dictionary mapping each column to the converter function\n",
    "converters = {col: convert_to_numpy_array for col in vector_column_labels}\n",
    "df = pd.read_csv(fname, converters=converters)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fire Name  Year Season Started Locations Affected  \\\n",
      "0         Cagua Fire  2020         Winter             Aragua   \n",
      "1      Vietnam Fires  2019         Summer            Da Nang   \n",
      "2    Chile Wildfires  2024         Winter          O'Higgins   \n",
      "3    Chile Wildfires  2024         Winter         Valparaíso   \n",
      "4    Chile Wildfires  2023         Winter              Maule   \n",
      "..               ...   ...            ...                ...   \n",
      "300              NaN  2020         Summer                 MB   \n",
      "301              NaN  2020         Summer                 MB   \n",
      "302              NaN  2020           Fall                 MB   \n",
      "303              NaN  2020         Summer                 NT   \n",
      "304              NaN  2020         Summer                 NT   \n",
      "\n",
      "                                      Temperature (F)  \\\n",
      "0    [75, 75, 73, 73, 72, 72, 71, 72, 72, 78, 82, 81]   \n",
      "1    [79, 81, 81, 82, 84, 86, 88, 90, 91, 93, 95, 97]   \n",
      "2    [78, 78, 78, 80, 82, 78, 77, 77, 77, 75, 73, 73]   \n",
      "3    [77, 81, 84, 88, 90, 90, 88, 86, 84, 81, 79, 75]   \n",
      "4    [72, 73, 73, 73, 75, 77, 75, 73, 70, 68, 64, 63]   \n",
      "..                                                ...   \n",
      "300  [54, 57, 59, 64, 68, 68, 72, 72, 73, 75, 75, 75]   \n",
      "301  [59, 59, 57, 59, 59, 66, 70, 72, 72, 73, 73, 72]   \n",
      "302  [37, 37, 37, 37, 39, 39, 41, 41, 43, 41, 39, 37]   \n",
      "303  [45, 45, 48, 52, 55, 55, 59, 61, 63, 63, 64, 63]   \n",
      "304  [63, 64, 66, 70, 73, 75, 79, 81, 82, 86, 88, 90]   \n",
      "\n",
      "                                         Dewpoint (F)  \\\n",
      "0    [75, 75, 76, 76, 76, 76, 76, 76, 75, 77, 77, 77]   \n",
      "1    [72, 73, 73, 73, 73, 75, 75, 75, 75, 75, 77, 77]   \n",
      "2      [22, 8, 12, 19, 20, 18, 16, 13, 7, 41, 38, 22]   \n",
      "3    [55, 54, 55, 54, 55, 55, 52, 54, 54, 54, 54, 54]   \n",
      "4    [59, 59, 59, 59, 59, 59, 57, 55, 55, 54, 52, 52]   \n",
      "..                                                ...   \n",
      "300    [0, 0, 57, 55, 52, 48, 46, 46, 48, 45, 45, 45]   \n",
      "301  [59, 59, 57, 59, 59, 64, 63, 59, 61, 63, 64, 61]   \n",
      "302  [37, 37, 36, 36, 36, 36, 36, 34, 34, 34, 36, 32]   \n",
      "303  [34, 32, 36, 36, 30, 34, 32, 36, 34, 34, 34, 36]   \n",
      "304  [55, 57, 57, 59, 59, 61, 61, 63, 61, 59, 59, 59]   \n",
      "\n",
      "                                          Humidity (%)  \\\n",
      "0     [85, 86, 86, 88, 90, 90, 94, 89, 74, 62, 55, 53]   \n",
      "1     [78, 79, 79, 74, 70, 70, 66, 62, 59, 56, 56, 53]   \n",
      "2     [74, 79, 84, 79, 74, 79, 83, 83, 83, 94, 94, 89]   \n",
      "3     [47, 39, 37, 31, 31, 31, 31, 31, 35, 39, 42, 47]   \n",
      "4     [64, 61, 61, 57, 57, 54, 53, 53, 60, 60, 64, 68]   \n",
      "..                                                 ...   \n",
      "300     [0, 0, 94, 73, 56, 49, 41, 41, 41, 34, 34, 34]   \n",
      "301  [100, 100, 100, 100, 100, 94, 78, 64, 69, 69, ...   \n",
      "302  [100, 100, 93, 93, 87, 87, 81, 76, 70, 76, 87,...   \n",
      "303   [66, 61, 62, 54, 38, 44, 36, 39, 34, 34, 32, 37]   \n",
      "304   [77, 77, 73, 68, 61, 61, 54, 54, 48, 40, 38, 36]   \n",
      "\n",
      "                                     Wind Speed (mph)  \\\n",
      "0                [2, 3, 3, 3, 4, 4, 2, 4, 2, 4, 6, 6]   \n",
      "1                [5, 6, 2, 5, 7, 5, 5, 7, 5, 6, 5, 2]   \n",
      "2    [18, 18, 20, 21, 20, 20, 20, 20, 17, 10, 11, 11]   \n",
      "3        [3, 6, 8, 12, 13, 15, 16, 18, 15, 15, 13, 9]   \n",
      "4    [13, 17, 18, 17, 21, 23, 21, 23, 18, 20, 17, 15]   \n",
      "..                                                ...   \n",
      "300              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "301              [3, 8, 9, 5, 9, 7, 2, 5, 2, 9, 7, 5]   \n",
      "302   [10, 10, 16, 14, 13, 8, 12, 13, 10, 10, 10, 10]   \n",
      "303             [8, 10, 2, 5, 3, 2, 3, 3, 3, 7, 8, 9]   \n",
      "304          [8, 9, 8, 7, 10, 10, 12, 9, 10, 7, 7, 5]   \n",
      "\n",
      "                                         Pressure (in)  \\\n",
      "0    [29.8, 29.83, 29.83, 29.86, 29.86, 29.8, 29.83...   \n",
      "1    [29.64, 29.64, 29.64, 29.64, 29.67, 29.67, 29....   \n",
      "2    [30.09, 30.09, 30.06, 30.06, 30.06, 30.06, 30....   \n",
      "3    [28.31, 28.31, 28.28, 28.25, 28.25, 28.22, 28....   \n",
      "4    [29.87, 29.84, 29.84, 29.84, 29.81, 29.81, 29....   \n",
      "..                                                 ...   \n",
      "300  [28.99, 29.0, 29.0, 29.01, 29.0, 28.99, 28.99,...   \n",
      "301  [28.49, 28.48, 28.5, 28.48, 28.46, 28.49, 28.4...   \n",
      "302  [28.7, 28.76, 28.81, 28.86, 28.89, 28.92, 28.9...   \n",
      "303  [29.19, 29.2, 29.21, 29.22, 29.22, 29.22, 29.2...   \n",
      "304  [29.51, 29.5, 29.49, 29.48, 29.46, 29.45, 29.4...   \n",
      "\n",
      "                       Percipitation (in)  \\\n",
      "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "..                                    ...   \n",
      "300  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "301  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "302  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "303  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "304  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "\n",
      "                                             Condition  Type Of Location  \\\n",
      "0    [Fair, Fair, Partly Cloudy, Fair, Fair, Partly...         Mounatins   \n",
      "1    [Fair, Fair, Fair, Fair, Windy, Windy, Windy, ...     Coastal Hills   \n",
      "2    [Fair, Partly Cloudy, Mostly Cloudy, Fair, Par...         Mountains   \n",
      "3    [Fair, Fair, Fair, Fair, Fair, Fair, Fair, Fai...  Coastal Mountain   \n",
      "4    [Fair, Fair, Fair, Fair, Windy, Windy, Windy, ...   Costal Mountain   \n",
      "..                                                 ...               ...   \n",
      "300  [Fog, Partly Cloudy, Fair, Fair, Partly Cloudy...               NaN   \n",
      "301  [Thunder, Thunder, Thunder, Light Rain with Th...               NaN   \n",
      "302  [Cloudy, Mist, Cloudy, Cloudy, Light Rain, Clo...               NaN   \n",
      "303  [Mostly Cloudy, Mostly Cloudy, Partly Cloudy, ...               NaN   \n",
      "304  [Partly Cloudy, Fair, Fair, Fair, Fair, Fair, ...               NaN   \n",
      "\n",
      "     Y-Value  \n",
      "0       Fire  \n",
      "1       Fire  \n",
      "2       Fire  \n",
      "3       Fire  \n",
      "4       Fire  \n",
      "..       ...  \n",
      "300  No Fire  \n",
      "301  No Fire  \n",
      "302  No Fire  \n",
      "303  No Fire  \n",
      "304  No Fire  \n",
      "\n",
      "[305 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_labels = [\"Season Started\", \"Locations Affected\", \"Condition\", \"Type Of Location\", \"Y-Value\"]\n",
    "categorical_scalar_column_labels = [\"Season Started\", \"Locations Affected\", \"Type Of Location\", \"Y-Value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season Started\n",
      "Summer    135\n",
      "Spring     75\n",
      "Fall       49\n",
      "Winter     46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Locations Affected\n",
      "California                23\n",
      "MB                        19\n",
      "BC                        19\n",
      "AB                        18\n",
      "Yellowknife               12\n",
      "                          ..\n",
      "North Rhine-Westphalia     1\n",
      "South Holland              1\n",
      "Hailey                     1\n",
      "Yosemite National Park     1\n",
      "Santa Rosa                 1\n",
      "Name: count, Length: 110, dtype: int64\n",
      "\n",
      "Type Of Location\n",
      "Forest               77\n",
      "Mountains            59\n",
      "Hills                16\n",
      "Arctic               11\n",
      "Coastal Forest       10\n",
      "Coastal Mountains    10\n",
      "Rainforest            8\n",
      "Flat                  8\n",
      "Plains                6\n",
      "Grasslands            6\n",
      "Costal Mountain       5\n",
      "Desert                4\n",
      "Swamp                 3\n",
      "Costal Forest         3\n",
      "Coastal Hills         3\n",
      "Coastal Lowland       2\n",
      "Coastal Mountain      1\n",
      "Mounatins             1\n",
      "Costal Mountains      1\n",
      "Coastal               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Y-Value\n",
      "Fire        155\n",
      "No Fire      93\n",
      "Not Fire     57\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cl in categorical_scalar_column_labels:\n",
    "    print(df[cl].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_columns = df[vector_column_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying all are ndarray\n",
    "is_ndarray = vector_columns.map(lambda x: isinstance(x, np.ndarray))\n",
    "is_ndarray.all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_shape = (12,)\n",
    "\n",
    "shape = vector_columns.map(lambda x: x.shape)\n",
    "# shape == desired_shape  # INVALID SYNTAX\n",
    "is_desired_shape = shape.map(lambda x: x == desired_shape)\n",
    "\n",
    "# Shorter version\n",
    "is_desired_shape = vector_columns.map(lambda x: x.shape == desired_shape)\n",
    "\n",
    "# Boolean series containing whether all vectors in that row are of the desired shape\n",
    "valid_shape_rows = is_desired_shape.all(axis=1)\n",
    "\n",
    "# Whether all vectors are of desired shape\n",
    "is_desired_shape.all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate minimum, average, and maximum values for specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fire Name  Year Season Started Locations Affected  \\\n",
      "0         Cagua Fire  2020         Winter             Aragua   \n",
      "1      Vietnam Fires  2019         Summer            Da Nang   \n",
      "2    Chile Wildfires  2024         Winter          O'Higgins   \n",
      "3    Chile Wildfires  2024         Winter         Valparaíso   \n",
      "4    Chile Wildfires  2023         Winter              Maule   \n",
      "..               ...   ...            ...                ...   \n",
      "300              NaN  2020         Summer                 MB   \n",
      "301              NaN  2020         Summer                 MB   \n",
      "302              NaN  2020           Fall                 MB   \n",
      "303              NaN  2020         Summer                 NT   \n",
      "304              NaN  2020         Summer                 NT   \n",
      "\n",
      "                                      Temperature (F)  Temperature (F)_min  \\\n",
      "0    [75, 75, 73, 73, 72, 72, 71, 72, 72, 78, 82, 81]                 71.0   \n",
      "1    [79, 81, 81, 82, 84, 86, 88, 90, 91, 93, 95, 97]                 79.0   \n",
      "2    [78, 78, 78, 80, 82, 78, 77, 77, 77, 75, 73, 73]                 73.0   \n",
      "3    [77, 81, 84, 88, 90, 90, 88, 86, 84, 81, 79, 75]                 75.0   \n",
      "4    [72, 73, 73, 73, 75, 77, 75, 73, 70, 68, 64, 63]                 63.0   \n",
      "..                                                ...                  ...   \n",
      "300  [54, 57, 59, 64, 68, 68, 72, 72, 73, 75, 75, 75]                 54.0   \n",
      "301  [59, 59, 57, 59, 59, 66, 70, 72, 72, 73, 73, 72]                 57.0   \n",
      "302  [37, 37, 37, 37, 39, 39, 41, 41, 43, 41, 39, 37]                 37.0   \n",
      "303  [45, 45, 48, 52, 55, 55, 59, 61, 63, 63, 64, 63]                 45.0   \n",
      "304  [63, 64, 66, 70, 73, 75, 79, 81, 82, 86, 88, 90]                 63.0   \n",
      "\n",
      "     Temperature (F)_avg  Temperature (F)_max  \\\n",
      "0              74.666667                 82.0   \n",
      "1              87.250000                 97.0   \n",
      "2              77.166667                 82.0   \n",
      "3              83.583333                 90.0   \n",
      "4              71.333333                 77.0   \n",
      "..                   ...                  ...   \n",
      "300            67.666667                 75.0   \n",
      "301            65.916667                 73.0   \n",
      "302            39.000000                 43.0   \n",
      "303            56.083333                 64.0   \n",
      "304            76.416667                 90.0   \n",
      "\n",
      "                                         Dewpoint (F)  Dewpoint (F)_min  ...  \\\n",
      "0    [75, 75, 76, 76, 76, 76, 76, 76, 75, 77, 77, 77]              75.0  ...   \n",
      "1    [72, 73, 73, 73, 73, 75, 75, 75, 75, 75, 77, 77]              72.0  ...   \n",
      "2      [22, 8, 12, 19, 20, 18, 16, 13, 7, 41, 38, 22]               7.0  ...   \n",
      "3    [55, 54, 55, 54, 55, 55, 52, 54, 54, 54, 54, 54]              52.0  ...   \n",
      "4    [59, 59, 59, 59, 59, 59, 57, 55, 55, 54, 52, 52]              52.0  ...   \n",
      "..                                                ...               ...  ...   \n",
      "300    [0, 0, 57, 55, 52, 48, 46, 46, 48, 45, 45, 45]               0.0  ...   \n",
      "301  [59, 59, 57, 59, 59, 64, 63, 59, 61, 63, 64, 61]              57.0  ...   \n",
      "302  [37, 37, 36, 36, 36, 36, 36, 34, 34, 34, 36, 32]              32.0  ...   \n",
      "303  [34, 32, 36, 36, 30, 34, 32, 36, 34, 34, 34, 36]              30.0  ...   \n",
      "304  [55, 57, 57, 59, 59, 61, 61, 63, 61, 59, 59, 59]              55.0  ...   \n",
      "\n",
      "     Pressure (in)_min  Pressure (in)_avg Pressure (in)_max  \\\n",
      "0                29.80          29.835000             29.86   \n",
      "1                29.64          29.652500             29.67   \n",
      "2                30.03          30.067500             30.09   \n",
      "3                28.22          28.252500             28.31   \n",
      "4                29.78          29.822500             29.87   \n",
      "..                 ...                ...               ...   \n",
      "300              28.95          28.982500             29.01   \n",
      "301              28.46          28.486667             28.50   \n",
      "302              28.70          28.914167             29.06   \n",
      "303              29.19          29.209167             29.22   \n",
      "304              29.37          29.442500             29.51   \n",
      "\n",
      "                       Percipitation (in)  Percipitation (in)_min  \\\n",
      "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                     0.0   \n",
      "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                     0.0   \n",
      "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                     0.0   \n",
      "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                     0.0   \n",
      "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                     0.0   \n",
      "..                                    ...                     ...   \n",
      "300  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                     0.0   \n",
      "301  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                     0.0   \n",
      "302  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                     0.0   \n",
      "303  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                     0.0   \n",
      "304  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                     0.0   \n",
      "\n",
      "     Percipitation (in)_avg Percipitation (in)_max  \\\n",
      "0                       0.0                    0.0   \n",
      "1                       0.0                    0.0   \n",
      "2                       0.0                    0.0   \n",
      "3                       0.0                    0.0   \n",
      "4                       0.0                    0.0   \n",
      "..                      ...                    ...   \n",
      "300                     0.0                    0.0   \n",
      "301                     0.0                    0.0   \n",
      "302                     0.0                    0.0   \n",
      "303                     0.0                    0.0   \n",
      "304                     0.0                    0.0   \n",
      "\n",
      "                                             Condition  Type Of Location  \\\n",
      "0    [Fair, Fair, Partly Cloudy, Fair, Fair, Partly...         Mounatins   \n",
      "1    [Fair, Fair, Fair, Fair, Windy, Windy, Windy, ...     Coastal Hills   \n",
      "2    [Fair, Partly Cloudy, Mostly Cloudy, Fair, Par...         Mountains   \n",
      "3    [Fair, Fair, Fair, Fair, Fair, Fair, Fair, Fai...  Coastal Mountain   \n",
      "4    [Fair, Fair, Fair, Fair, Windy, Windy, Windy, ...   Costal Mountain   \n",
      "..                                                 ...               ...   \n",
      "300  [Fog, Partly Cloudy, Fair, Fair, Partly Cloudy...               NaN   \n",
      "301  [Thunder, Thunder, Thunder, Light Rain with Th...               NaN   \n",
      "302  [Cloudy, Mist, Cloudy, Cloudy, Light Rain, Clo...               NaN   \n",
      "303  [Mostly Cloudy, Mostly Cloudy, Partly Cloudy, ...               NaN   \n",
      "304  [Partly Cloudy, Fair, Fair, Fair, Fair, Fair, ...               NaN   \n",
      "\n",
      "     Y-Value  \n",
      "0       Fire  \n",
      "1       Fire  \n",
      "2       Fire  \n",
      "3       Fire  \n",
      "4       Fire  \n",
      "..       ...  \n",
      "300  No Fire  \n",
      "301  No Fire  \n",
      "302  No Fire  \n",
      "303  No Fire  \n",
      "304  No Fire  \n",
      "\n",
      "[305 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Columns to generate stats for\n",
    "columns_to_process = numerical_vector_column_labels\n",
    "\n",
    "# Function to compute min, avg, and max and return as a Series\n",
    "def compute_stats(arr):\n",
    "    return pd.Series([np.min(arr), np.mean(arr), np.max(arr)], index=['min', 'avg', 'max'])\n",
    "\n",
    "# New DataFrame to store results\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over specified columns\n",
    "for col in df.columns:\n",
    "    # If the column contains numpy arrays and is in the columns to process\n",
    "    if col in columns_to_process:  # and np.issubdtype(df[col].dtype, np.ndarray)\n",
    "        # Compute statistics for each numpy array element in the column\n",
    "        stats = df[col].apply(compute_stats)\n",
    "        # Rename columns to include the statistics\n",
    "        stats.columns = [f\"{col}_min\", f\"{col}_avg\", f\"{col}_max\"]\n",
    "        # Concatenate the statistics columns with the original column and insert them into the new DataFrame\n",
    "        new_df = pd.concat([new_df, df[col], stats], axis=1)\n",
    "    else:\n",
    "        # If not a numpy array column or not in columns to process, copy it to the new DataFrame\n",
    "        new_df[col] = df[col]\n",
    "\n",
    "print(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking element values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire Name                 150\n",
      "Year                        0\n",
      "Season Started              0\n",
      "Locations Affected          0\n",
      "Temperature (F)             0\n",
      "Temperature (F)_min         0\n",
      "Temperature (F)_avg         0\n",
      "Temperature (F)_max         0\n",
      "Dewpoint (F)                0\n",
      "Dewpoint (F)_min            0\n",
      "Dewpoint (F)_avg            0\n",
      "Dewpoint (F)_max            0\n",
      "Humidity (%)                0\n",
      "Humidity (%)_min            0\n",
      "Humidity (%)_avg            0\n",
      "Humidity (%)_max            0\n",
      "Wind Speed (mph)            0\n",
      "Wind Speed (mph)_min        0\n",
      "Wind Speed (mph)_avg        0\n",
      "Wind Speed (mph)_max        0\n",
      "Pressure (in)               0\n",
      "Pressure (in)_min           0\n",
      "Pressure (in)_avg           0\n",
      "Pressure (in)_max           0\n",
      "Percipitation (in)          0\n",
      "Percipitation (in)_min      0\n",
      "Percipitation (in)_avg      0\n",
      "Percipitation (in)_max      0\n",
      "Condition                   0\n",
      "Type Of Location           70\n",
      "Y-Value                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Only select for columns where we care if values are missing (do not care if we are missing Fire Name)\n",
    "isna = df.loc[:, \"Year\":\"Y-Value\"].isna()\n",
    "isna.sum()[isna.any()]\n",
    "print(df.isna().sum())\n",
    "\n",
    "# print(df['Type Of Location'].dtype)\n",
    "# df = df.fillna('NaaN')\n",
    "# df.drop(df[df['Type Of Location'] == 'NaaN'].index, inplace = True)\n",
    "# print(df['Type Of Location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking contents for numpy arrays (numerical only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not df[numerical_vector_column_labels].map(lambda x: np.any(np.isnan(x))).any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dealing with duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dealing with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy\n",
    "coded_df = df.copy(deep=True).drop(['Fire Name'], axis=1)\n",
    "for col in coded_df.columns:\n",
    "    if 'min' in col or 'max' in col or 'avg' in col:\n",
    "        coded_df = coded_df.drop([col], axis=1)\n",
    "# coded_df = pd.DataFrame()\n",
    "unencoded_df = df.copy(deep=True)\n",
    "\n",
    "# Replace y value\n",
    "with pd.option_context('future.no_silent_downcasting', True):\n",
    "    fire_map = {'Fire': 1, 'Fire\\r\\n': 1, 'No Fire': 0, 'Not Fire': 0}\n",
    "    coded_df['Y-Value_encoded'] = unencoded_df['Y-Value'].replace(fire_map).astype(int)\n",
    "    coded_df['Y-Value_encoded'].value_counts()\n",
    "    coded_df = coded_df.drop(['Y-Value'], axis=1)\n",
    "\n",
    "# Keep track of newly added columns\n",
    "added_cols = []\n",
    "\n",
    "cat_scal_col_labels = [\"Season Started\", \"Locations Affected\", \"Type Of Location\"]\n",
    "\n",
    "# Columns containing single categorical values\n",
    "for cl in cat_scal_col_labels:\n",
    "    onehot = pd.get_dummies(coded_df[cl])\n",
    "    oh_list = []\n",
    "    for new_col in list(onehot):\n",
    "        oh_list.append(f'{cl}_{new_col}')\n",
    "    added_cols = added_cols + list(onehot.columns)\n",
    "    coded_df = pd.get_dummies(coded_df,columns=[cl], prefix='', prefix_sep='')\n",
    "\n",
    "\n",
    "global_col = ''\n",
    "\n",
    "\n",
    "def condition_count(x) -> int:\n",
    "    return int(x['Condition'].tolist().count(global_col))\n",
    "\n",
    "# Columns containing categorical vector values\n",
    "for cl in categorical_vector_column_labels:\n",
    "    unique = np.unique(np.concatenate(df[cl].values)).tolist()\n",
    "    unique = list(filter(None, unique))\n",
    "    for new_col in unique:\n",
    "        global_col = new_col\n",
    "        coded_df[new_col] = coded_df.apply(condition_count, axis=1)\n",
    "        added_cols.append(new_col)\n",
    "\n",
    "    coded_df = coded_df.drop(cl, axis=1)\n",
    "\n",
    "\n",
    "# coded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 239)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14622/2993395270.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  coded_df[new_columns] = pd.DataFrame(coded_df[col].tolist(), columns=new_columns)\n",
      "/tmp/ipykernel_14622/2993395270.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  coded_df[new_columns] = pd.DataFrame(coded_df[col].tolist(), columns=new_columns)\n",
      "/tmp/ipykernel_14622/2993395270.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  coded_df[new_columns] = pd.DataFrame(coded_df[col].tolist(), columns=new_columns)\n",
      "/tmp/ipykernel_14622/2993395270.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  coded_df[new_columns] = pd.DataFrame(coded_df[col].tolist(), columns=new_columns)\n",
      "/tmp/ipykernel_14622/2993395270.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  coded_df[new_columns] = pd.DataFrame(coded_df[col].tolist(), columns=new_columns)\n",
      "/tmp/ipykernel_14622/2993395270.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  coded_df[new_columns] = pd.DataFrame(coded_df[col].tolist(), columns=new_columns)\n",
      "/tmp/ipykernel_14622/2993395270.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  coded_df[new_columns] = pd.DataFrame(coded_df[col].tolist(), columns=new_columns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Y-Value_encoded</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Spring</th>\n",
       "      <th>Summer</th>\n",
       "      <th>Winter</th>\n",
       "      <th>AB</th>\n",
       "      <th>Acre</th>\n",
       "      <th>Alabama</th>\n",
       "      <th>Alaska</th>\n",
       "      <th>...</th>\n",
       "      <th>Percipitation (in)2</th>\n",
       "      <th>Percipitation (in)3</th>\n",
       "      <th>Percipitation (in)4</th>\n",
       "      <th>Percipitation (in)5</th>\n",
       "      <th>Percipitation (in)6</th>\n",
       "      <th>Percipitation (in)7</th>\n",
       "      <th>Percipitation (in)8</th>\n",
       "      <th>Percipitation (in)9</th>\n",
       "      <th>Percipitation (in)10</th>\n",
       "      <th>Percipitation (in)11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Y-Value_encoded   Fall  Spring  Summer  Winter     AB   Acre  \\\n",
       "0    2020                1  False   False   False    True  False  False   \n",
       "1    2019                1  False   False    True   False  False  False   \n",
       "2    2024                1  False   False   False    True  False  False   \n",
       "3    2024                1  False   False   False    True  False  False   \n",
       "4    2023                1  False   False   False    True  False  False   \n",
       "..    ...              ...    ...     ...     ...     ...    ...    ...   \n",
       "300  2020                0  False   False    True   False  False  False   \n",
       "301  2020                0  False   False    True   False  False  False   \n",
       "302  2020                0   True   False   False   False  False  False   \n",
       "303  2020                0  False   False    True   False  False  False   \n",
       "304  2020                0  False   False    True   False  False  False   \n",
       "\n",
       "     Alabama  Alaska  ...  Percipitation (in)2  Percipitation (in)3  \\\n",
       "0      False   False  ...                  0.0                  0.0   \n",
       "1      False   False  ...                  0.0                  0.0   \n",
       "2      False   False  ...                  0.0                  0.0   \n",
       "3      False   False  ...                  0.0                  0.0   \n",
       "4      False   False  ...                  0.0                  0.0   \n",
       "..       ...     ...  ...                  ...                  ...   \n",
       "300    False   False  ...                  0.0                  0.0   \n",
       "301    False   False  ...                  0.0                  0.0   \n",
       "302    False   False  ...                  0.0                  0.0   \n",
       "303    False   False  ...                  0.0                  0.0   \n",
       "304    False   False  ...                  0.0                  0.0   \n",
       "\n",
       "     Percipitation (in)4  Percipitation (in)5  Percipitation (in)6  \\\n",
       "0                    0.0                  0.0                  0.0   \n",
       "1                    0.0                  0.0                  0.0   \n",
       "2                    0.0                  0.0                  0.0   \n",
       "3                    0.0                  0.0                  0.0   \n",
       "4                    0.0                  0.0                  0.0   \n",
       "..                   ...                  ...                  ...   \n",
       "300                  0.0                  0.0                  0.0   \n",
       "301                  0.0                  0.0                  0.0   \n",
       "302                  0.0                  0.0                  0.0   \n",
       "303                  0.0                  0.0                  0.0   \n",
       "304                  0.0                  0.0                  0.0   \n",
       "\n",
       "     Percipitation (in)7  Percipitation (in)8  Percipitation (in)9  \\\n",
       "0                    0.0                  0.0                  0.0   \n",
       "1                    0.0                  0.0                  0.0   \n",
       "2                    0.0                  0.0                  0.0   \n",
       "3                    0.0                  0.0                  0.0   \n",
       "4                    0.0                  0.0                  0.0   \n",
       "..                   ...                  ...                  ...   \n",
       "300                  0.0                  0.0                  0.0   \n",
       "301                  0.0                  0.0                  0.0   \n",
       "302                  0.0                  0.0                  0.0   \n",
       "303                  0.0                  0.0                  0.0   \n",
       "304                  0.0                  0.0                  0.0   \n",
       "\n",
       "     Percipitation (in)10  Percipitation (in)11  \n",
       "0                     0.0                   0.0  \n",
       "1                     0.0                   0.0  \n",
       "2                     0.0                   0.0  \n",
       "3                     0.0                   0.0  \n",
       "4                     0.0                   0.0  \n",
       "..                    ...                   ...  \n",
       "300                   0.0                   0.0  \n",
       "301                   0.0                   0.0  \n",
       "302                   0.0                   0.0  \n",
       "303                   0.0                   0.0  \n",
       "304                   0.0                   0.0  \n",
       "\n",
       "[305 rows x 239 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def str_to_list(x):\n",
    "    test = ''\n",
    "    if type(x) == type(test):\n",
    "        values = x.replace(',','').replace('[','').replace(']','').split(' ')\n",
    "        values = list(filter(None, values))\n",
    "    else:\n",
    "        values = x\n",
    "    # Remove empty strings\n",
    "    l = [float(val) for val in values]\n",
    "    return l\n",
    "\n",
    "def arr_to_intlist(x):\n",
    "    l = [int(val) for val in x]\n",
    "    return l\n",
    "\n",
    "list_columns = numerical_vector_column_labels\n",
    "\n",
    "# First split numerical columns\n",
    "for col in list_columns:\n",
    "    if (df[col].dtype == 'object'):\n",
    "        df[col] = df[col].apply(str_to_list if col != 'Condition' else arr_to_intlist)\n",
    "    \n",
    "    new_columns = [col + str(x) for x in range(12)]\n",
    "    added_cols = added_cols + new_columns\n",
    "    coded_df[new_columns] = pd.DataFrame(coded_df[col].tolist(), columns=new_columns)\n",
    "    coded_df = coded_df.drop([col], axis=1)\n",
    "\n",
    "print(coded_df.shape)\n",
    "coded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dealing with Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Partitioning a data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year <class 'str'>\n",
      "Y-Value_encoded <class 'str'>\n",
      "Fall <class 'str'>\n",
      "Spring <class 'str'>\n",
      "Summer <class 'str'>\n",
      "Winter <class 'str'>\n",
      "AB <class 'str'>\n",
      "Acre <class 'str'>\n",
      "Alabama <class 'str'>\n",
      "Alaska <class 'str'>\n",
      "Alberta <class 'str'>\n",
      "Amazonas <class 'str'>\n",
      "Aragua <class 'str'>\n",
      "Araucania <class 'str'>\n",
      "Arizona <class 'str'>\n",
      "Arizona and New Mexico <class 'str'>\n",
      "Arkansas <class 'str'>\n",
      "Ashcroft <class 'str'>\n",
      "Ashland <class 'str'>\n",
      "BC <class 'str'>\n",
      "Belize <class 'str'>\n",
      "Black Forest <class 'str'>\n",
      "British Columbia <class 'str'>\n",
      "British Columbia and Alberta <class 'str'>\n",
      "Bulgakovsky <class 'str'>\n",
      "CA <class 'str'>\n",
      "California <class 'str'>\n",
      "California and Oregon <class 'str'>\n",
      "Challis <class 'str'>\n",
      "Colorado <class 'str'>\n",
      "Córdoba <class 'str'>\n",
      "DC <class 'str'>\n",
      "Da Nang <class 'str'>\n",
      "Florida <class 'str'>\n",
      "Fort McMurray <class 'str'>\n",
      "Grand Lake <class 'str'>\n",
      "Guanajuato <class 'str'>\n",
      "Hailey <class 'str'>\n",
      "Heilongjiang <class 'str'>\n",
      "IL <class 'str'>\n",
      "Idaho <class 'str'>\n",
      "Idaho and Nevada <class 'str'>\n",
      "Jordan Valley <class 'str'>\n",
      "Kamloops <class 'str'>\n",
      "Kemerovo <class 'str'>\n",
      "Luxembourg <class 'str'>\n",
      "Lyon <class 'str'>\n",
      "MA <class 'str'>\n",
      "MB <class 'str'>\n",
      "MN <class 'str'>\n",
      "Malibu <class 'str'>\n",
      "Manitoba <class 'str'>\n",
      "Mato Grosso do Sul <class 'str'>\n",
      "Maule <class 'str'>\n",
      "Meghalaya <class 'str'>\n",
      "Mendocino <class 'str'>\n",
      "Mexico <class 'str'>\n",
      "Minnesota <class 'str'>\n",
      "Mississipi <class 'str'>\n",
      "Montana <class 'str'>\n",
      "Myagdi <class 'str'>\n",
      "NF <class 'str'>\n",
      "NT <class 'str'>\n",
      "NY <class 'str'>\n",
      "New Jersey <class 'str'>\n",
      "New Mexico <class 'str'>\n",
      "New York <class 'str'>\n",
      "North Carolina <class 'str'>\n",
      "North Rhine-Westphalia <class 'str'>\n",
      "Nuevo León <class 'str'>\n",
      "O'Higgins <class 'str'>\n",
      "ON <class 'str'>\n",
      "OR <class 'str'>\n",
      "Okanogan County <class 'str'>\n",
      "Oklahoma <class 'str'>\n",
      "Ontario <class 'str'>\n",
      "Oregon <class 'str'>\n",
      "Oro Valley <class 'str'>\n",
      "Pando <class 'str'>\n",
      "Paradise <class 'str'>\n",
      "Patagonia <class 'str'>\n",
      "Pennsylvania <class 'str'>\n",
      "Prescott <class 'str'>\n",
      "QC <class 'str'>\n",
      "Quebec <class 'str'>\n",
      "Ravendale <class 'str'>\n",
      "Redding <class 'str'>\n",
      "Rondônia <class 'str'>\n",
      "SK <class 'str'>\n",
      "Santa Barbara <class 'str'>\n",
      "Santa Rosa <class 'str'>\n",
      "Santiago del Estero <class 'str'>\n",
      "Scotland <class 'str'>\n",
      "South Carolina <class 'str'>\n",
      "South Dakota <class 'str'>\n",
      "South Holland <class 'str'>\n",
      "TX <class 'str'>\n",
      "Tennessee <class 'str'>\n",
      "Texas <class 'str'>\n",
      "Toronto <class 'str'>\n",
      "Ulaanbaatar <class 'str'>\n",
      "Utah <class 'str'>\n",
      "Valparaíso <class 'str'>\n",
      "WA <class 'str'>\n",
      "WY <class 'str'>\n",
      "Washington <class 'str'>\n",
      "West Virginia <class 'str'>\n",
      "Wisconsin <class 'str'>\n",
      "Wyoming <class 'str'>\n",
      "Wyoming and Montana <class 'str'>\n",
      "YT <class 'str'>\n",
      "Yakima <class 'str'>\n",
      "Yakutsk <class 'str'>\n",
      "Yarnell <class 'str'>\n",
      "Yellowknife <class 'str'>\n",
      "Yosemite National Park <class 'str'>\n",
      "Arctic <class 'str'>\n",
      "Coastal <class 'str'>\n",
      "Coastal Forest <class 'str'>\n",
      "Coastal Hills <class 'str'>\n",
      "Coastal Lowland <class 'str'>\n",
      "Coastal Mountain <class 'str'>\n",
      "Coastal Mountains <class 'str'>\n",
      "Costal Forest <class 'str'>\n",
      "Costal Mountain <class 'str'>\n",
      "Costal Mountains <class 'str'>\n",
      "Desert <class 'str'>\n",
      "Flat <class 'str'>\n",
      "Forest <class 'str'>\n",
      "Grasslands <class 'str'>\n",
      "Hills <class 'str'>\n",
      "Mounatins <class 'str'>\n",
      "Mountains <class 'str'>\n",
      "Plains <class 'str'>\n",
      "Rainforest <class 'str'>\n",
      "Swamp <class 'str'>\n",
      "Cloudy <class 'str'>\n",
      "Cloudy / Windy <class 'str'>\n",
      "Drifting Snow <class 'str'>\n",
      "Fair <class 'str'>\n",
      "Fair / Windy <class 'str'>\n",
      "Fair Fair <class 'str'>\n",
      "Fog <class 'str'>\n",
      "Haze <class 'str'>\n",
      "Ice Crystals <class 'str'>\n",
      "Light Rain <class 'str'>\n",
      "Light Rain / Windy <class 'str'>\n",
      "Light Rain Shower <class 'str'>\n",
      "Light Rain with Thunder <class 'str'>\n",
      "Light Snow <class 'str'>\n",
      "Mist <class 'str'>\n",
      "Mostly Cloud <class 'str'>\n",
      "Mostly Cloudy <class 'str'>\n",
      "Mostly Cloudy / Windy <class 'str'>\n",
      "Mostly Coudy <class 'str'>\n",
      "N/A <class 'str'>\n",
      "Partly Cloudy <class 'str'>\n",
      "Partly Cloudy / Windy <class 'str'>\n",
      "Patches of Fog <class 'str'>\n",
      "Rain <class 'str'>\n",
      "Showers in the Vicinity <class 'str'>\n",
      "Smoke <class 'str'>\n",
      "Smoke / Windy <class 'str'>\n",
      "T-Storm <class 'str'>\n",
      "Thunder <class 'str'>\n",
      "Thunder in the Vicinity <class 'str'>\n",
      "Windy <class 'str'>\n",
      "Temperature (F)0 <class 'str'>\n",
      "Temperature (F)1 <class 'str'>\n",
      "Temperature (F)2 <class 'str'>\n",
      "Temperature (F)3 <class 'str'>\n",
      "Temperature (F)4 <class 'str'>\n",
      "Temperature (F)5 <class 'str'>\n",
      "Temperature (F)6 <class 'str'>\n",
      "Temperature (F)7 <class 'str'>\n",
      "Temperature (F)8 <class 'str'>\n",
      "Temperature (F)9 <class 'str'>\n",
      "Temperature (F)10 <class 'str'>\n",
      "Temperature (F)11 <class 'str'>\n",
      "Dewpoint (F)0 <class 'str'>\n",
      "Dewpoint (F)1 <class 'str'>\n",
      "Dewpoint (F)2 <class 'str'>\n",
      "Dewpoint (F)3 <class 'str'>\n",
      "Dewpoint (F)4 <class 'str'>\n",
      "Dewpoint (F)5 <class 'str'>\n",
      "Dewpoint (F)6 <class 'str'>\n",
      "Dewpoint (F)7 <class 'str'>\n",
      "Dewpoint (F)8 <class 'str'>\n",
      "Dewpoint (F)9 <class 'str'>\n",
      "Dewpoint (F)10 <class 'str'>\n",
      "Dewpoint (F)11 <class 'str'>\n",
      "Humidity (%)0 <class 'str'>\n",
      "Humidity (%)1 <class 'str'>\n",
      "Humidity (%)2 <class 'str'>\n",
      "Humidity (%)3 <class 'str'>\n",
      "Humidity (%)4 <class 'str'>\n",
      "Humidity (%)5 <class 'str'>\n",
      "Humidity (%)6 <class 'str'>\n",
      "Humidity (%)7 <class 'str'>\n",
      "Humidity (%)8 <class 'str'>\n",
      "Humidity (%)9 <class 'str'>\n",
      "Humidity (%)10 <class 'str'>\n",
      "Humidity (%)11 <class 'str'>\n",
      "Wind Speed (mph)0 <class 'str'>\n",
      "Wind Speed (mph)1 <class 'str'>\n",
      "Wind Speed (mph)2 <class 'str'>\n",
      "Wind Speed (mph)3 <class 'str'>\n",
      "Wind Speed (mph)4 <class 'str'>\n",
      "Wind Speed (mph)5 <class 'str'>\n",
      "Wind Speed (mph)6 <class 'str'>\n",
      "Wind Speed (mph)7 <class 'str'>\n",
      "Wind Speed (mph)8 <class 'str'>\n",
      "Wind Speed (mph)9 <class 'str'>\n",
      "Wind Speed (mph)10 <class 'str'>\n",
      "Wind Speed (mph)11 <class 'str'>\n",
      "Pressure (in)0 <class 'str'>\n",
      "Pressure (in)1 <class 'str'>\n",
      "Pressure (in)2 <class 'str'>\n",
      "Pressure (in)3 <class 'str'>\n",
      "Pressure (in)4 <class 'str'>\n",
      "Pressure (in)5 <class 'str'>\n",
      "Pressure (in)6 <class 'str'>\n",
      "Pressure (in)7 <class 'str'>\n",
      "Pressure (in)8 <class 'str'>\n",
      "Pressure (in)9 <class 'str'>\n",
      "Pressure (in)10 <class 'str'>\n",
      "Pressure (in)11 <class 'str'>\n",
      "Percipitation (in)0 <class 'str'>\n",
      "Percipitation (in)1 <class 'str'>\n",
      "Percipitation (in)2 <class 'str'>\n",
      "Percipitation (in)3 <class 'str'>\n",
      "Percipitation (in)4 <class 'str'>\n",
      "Percipitation (in)5 <class 'str'>\n",
      "Percipitation (in)6 <class 'str'>\n",
      "Percipitation (in)7 <class 'str'>\n",
      "Percipitation (in)8 <class 'str'>\n",
      "Percipitation (in)9 <class 'str'>\n",
      "Percipitation (in)10 <class 'str'>\n",
      "Percipitation (in)11 <class 'str'>\n",
      "['str']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_var = 'Y-Value_encoded'\n",
    "feature_var = added_cols\n",
    "\n",
    "feature_names = np.asarray(coded_df.columns, dtype=object)\n",
    "types = sorted(t.__qualname__ for t in set(type(v) for v in feature_names))\n",
    "for v in feature_names:\n",
    "    print(v, type(v))\n",
    "print(types)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(coded_df[feature_var], coded_df[target_var], test_size=0.2, shuffle=True, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores are [0.8        0.68       0.68       0.72       0.625      0.58333333\n",
      " 0.79166667 0.58333333 0.75       0.83333333]\n",
      "The average KFold scores is 0.7046666666666666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCV accuracy scores are\u001b[39m\u001b[38;5;124m'\u001b[39m, cross_val_score(model, X_train, y_train, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m kfold, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe average KFold scores is\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(cross_val_score(model, X_train, y_train, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mkfold, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe average LOOCV score is\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe average RepeatedKFold score is\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(cross_val_score(model, X_train, y_train, cv\u001b[38;5;241m=\u001b[39mrepeatkf, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "repeatkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=6969)\n",
    "\n",
    "model = GaussianNB()\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print('CV accuracy scores are', cross_val_score(model, X_train, y_train, scoring='accuracy', cv= kfold, n_jobs=-1))\n",
    "\n",
    "print('The average KFold scores is', np.mean(cross_val_score(model, X_train, y_train, scoring='accuracy', cv=kfold, n_jobs=-1)))\n",
    "print('The average LOOCV score is', np.mean(cross_val_score(model, X_train, y_train, scoring='accuracy', cv=loo, n_jobs=-1)))\n",
    "print('The average RepeatedKFold score is', np.mean(cross_val_score(model, X_train, y_train, cv=repeatkf, n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Set parameter to be searched in a range\n",
    "params = {'n_neighbors': range(1,150)}\n",
    "\n",
    "# Initiate the KNN model and GridSearchCV function\n",
    "knn = KNeighborsClassifier()\n",
    "grid_knn = GridSearchCV(estimator=knn, param_grid=params,\n",
    "                        scoring='accuracy', cv=5)\n",
    "\n",
    "# Fit the function to train set \n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# Find the best parameter and see how well it performs on test set\n",
    "print(grid_knn.best_params_)\n",
    "print(grid_knn.score(X_test, y_test))\n",
    "print(grid_knn.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = []\n",
    "n_iterations = 1000\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    X_sparse, y_sparse = resample(X_test, y_test, replace=True)\n",
    "    predict = model.predict(X_sparse)\n",
    "    score = accuracy_score(y_sparse, predict)\n",
    "    accuracy.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find median\n",
    "median = np.median(accuracy)\n",
    "\n",
    "# Find lower and upper bounds\n",
    "lower = np.percentile(accuracy, 2.5)\n",
    "upper = np.percentile(accuracy, 97.5)\n",
    "\n",
    "print(f'The median is {median:.2f} '\n",
    "      f'with confidence intervals of [{lower:.2f}, {upper:.2f}].')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.kdeplot(accuracy)\n",
    "plt.title('1000 Bootstrap Samples of Test Set')\n",
    "plt.xlabel('Accuracy of GaussianNB')\n",
    "plt.axvline(median, 0, 16, linestyle=\"--\")\n",
    "plt.axvline(lower, 0, 16, linestyle=\"--\", color=\"red\")\n",
    "plt.axvline(upper, 0, 16, linestyle=\"--\", color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
