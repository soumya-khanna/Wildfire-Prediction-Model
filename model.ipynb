{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 13)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast #for strings\n",
    "import re #regex\n",
    "\n",
    "fname='MSCI446_ Data - Sheet1.csv'\n",
    "\n",
    "def convert_to_numpy_array(string: str):\n",
    "    # Verify string is written like a python list\n",
    "    stripped = string.strip()\n",
    "    pattern = r\"\\[(.*)\\]\"\n",
    "    match = re.match(pattern, stripped)\n",
    "    if not match:\n",
    "        raise NotImplementedError(f\"{stripped}\")\n",
    "    # Group 1 captures the content inside the square brackets\n",
    "    contents = match.group(1)\n",
    "    \n",
    "    try:\n",
    "        # Use ast.literal_eval to safely evaluate string literals\n",
    "        evaluated = ast.literal_eval(stripped)\n",
    "        if type(evaluated) is not list:\n",
    "            raise NotImplementedError()\n",
    "        # series = pd.Series(evaluated)\n",
    "        return np.array(evaluated)\n",
    "    except (SyntaxError, ValueError):  # this occurs with the \"Condition\" column\n",
    "        # If parsing as a list fails, split the contents within the square brackets by comma, \n",
    "        # interpret each value as a string and strip whitespace\n",
    "        return np.array([ item.strip() for item in contents.split(',') ])\n",
    "\n",
    "# Read CSV file with the custom function\n",
    "numerical_vector_column_labels = ['Temperature (F)', 'Dewpoint (F)', 'Humidity (%)', 'Wind Speed (mph)', 'Pressure (in)', 'Percipitation (in)']\n",
    "categorical_vector_column_labels = [\"Condition\"]\n",
    "vector_column_labels = numerical_vector_column_labels + categorical_vector_column_labels\n",
    "\n",
    "# Create a converters dictionary mapping each column to the converter function\n",
    "converters = {col: convert_to_numpy_array for col in vector_column_labels}\n",
    "df = pd.read_csv(fname, converters=converters)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fire Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season Started</th>\n",
       "      <th>Locations Affected</th>\n",
       "      <th>Temperature (F)</th>\n",
       "      <th>Dewpoint (F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Wind Speed (mph)</th>\n",
       "      <th>Pressure (in)</th>\n",
       "      <th>Percipitation (in)</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Type Of Location</th>\n",
       "      <th>Y-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cagua Fire</td>\n",
       "      <td>2020</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Aragua</td>\n",
       "      <td>[75, 75, 73, 73, 72, 72, 71, 72, 72, 78, 82, 81]</td>\n",
       "      <td>[75, 75, 76, 76, 76, 76, 76, 76, 75, 77, 77, 77]</td>\n",
       "      <td>[85, 86, 86, 88, 90, 90, 94, 89, 74, 62, 55, 53]</td>\n",
       "      <td>[2, 3, 3, 3, 4, 4, 2, 4, 2, 4, 6, 6]</td>\n",
       "      <td>[29.8, 29.83, 29.83, 29.86, 29.86, 29.8, 29.83...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[Fair, Fair, Partly Cloudy, Fair, Fair, Partly...</td>\n",
       "      <td>Mounatins</td>\n",
       "      <td>Fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vietnam Fires</td>\n",
       "      <td>2019</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Da Nang</td>\n",
       "      <td>[79, 81, 81, 82, 84, 86, 88, 90, 91, 93, 95, 97]</td>\n",
       "      <td>[72, 73, 73, 73, 73, 75, 75, 75, 75, 75, 77, 77]</td>\n",
       "      <td>[78, 79, 79, 74, 70, 70, 66, 62, 59, 56, 56, 53]</td>\n",
       "      <td>[5, 6, 2, 5, 7, 5, 5, 7, 5, 6, 5, 2]</td>\n",
       "      <td>[29.64, 29.64, 29.64, 29.64, 29.67, 29.67, 29....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[Fair, Fair, Fair, Fair, Windy, Windy, Windy, ...</td>\n",
       "      <td>Coastal Hills</td>\n",
       "      <td>Fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chile Wildfires</td>\n",
       "      <td>2024</td>\n",
       "      <td>Winter</td>\n",
       "      <td>O'Higgins</td>\n",
       "      <td>[78, 78, 78, 80, 82, 78, 77, 77, 77, 75, 73, 73]</td>\n",
       "      <td>[22, 8, 12, 19, 20, 18, 16, 13, 7, 41, 38, 22]</td>\n",
       "      <td>[74, 79, 84, 79, 74, 79, 83, 83, 83, 94, 94, 89]</td>\n",
       "      <td>[18, 18, 20, 21, 20, 20, 20, 20, 17, 10, 11, 11]</td>\n",
       "      <td>[30.09, 30.09, 30.06, 30.06, 30.06, 30.06, 30....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[Fair, Partly Cloudy, Mostly Cloudy, Fair, Par...</td>\n",
       "      <td>Mountains</td>\n",
       "      <td>Fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chile Wildfires</td>\n",
       "      <td>2024</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Valparaíso</td>\n",
       "      <td>[77, 81, 84, 88, 90, 90, 88, 86, 84, 81, 79, 75]</td>\n",
       "      <td>[55, 54, 55, 54, 55, 55, 52, 54, 54, 54, 54, 54]</td>\n",
       "      <td>[47, 39, 37, 31, 31, 31, 31, 31, 35, 39, 42, 47]</td>\n",
       "      <td>[3, 6, 8, 12, 13, 15, 16, 18, 15, 15, 13, 9]</td>\n",
       "      <td>[28.31, 28.31, 28.28, 28.25, 28.25, 28.22, 28....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[Fair, Fair, Fair, Fair, Fair, Fair, Fair, Fai...</td>\n",
       "      <td>Coastal Mountain</td>\n",
       "      <td>Fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chile Wildfires</td>\n",
       "      <td>2023</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Maule</td>\n",
       "      <td>[72, 73, 73, 73, 75, 77, 75, 73, 70, 68, 64, 63]</td>\n",
       "      <td>[59, 59, 59, 59, 59, 59, 57, 55, 55, 54, 52, 52]</td>\n",
       "      <td>[64, 61, 61, 57, 57, 54, 53, 53, 60, 60, 64, 68]</td>\n",
       "      <td>[13, 17, 18, 17, 21, 23, 21, 23, 18, 20, 17, 15]</td>\n",
       "      <td>[29.87, 29.84, 29.84, 29.84, 29.81, 29.81, 29....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[Fair, Fair, Fair, Fair, Windy, Windy, Windy, ...</td>\n",
       "      <td>Costal Mountain</td>\n",
       "      <td>Fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Fire Name  Year Season Started Locations Affected  \\\n",
       "0       Cagua Fire  2020         Winter             Aragua   \n",
       "1    Vietnam Fires  2019         Summer            Da Nang   \n",
       "2  Chile Wildfires  2024         Winter          O'Higgins   \n",
       "3  Chile Wildfires  2024         Winter         Valparaíso   \n",
       "4  Chile Wildfires  2023         Winter              Maule   \n",
       "\n",
       "                                    Temperature (F)  \\\n",
       "0  [75, 75, 73, 73, 72, 72, 71, 72, 72, 78, 82, 81]   \n",
       "1  [79, 81, 81, 82, 84, 86, 88, 90, 91, 93, 95, 97]   \n",
       "2  [78, 78, 78, 80, 82, 78, 77, 77, 77, 75, 73, 73]   \n",
       "3  [77, 81, 84, 88, 90, 90, 88, 86, 84, 81, 79, 75]   \n",
       "4  [72, 73, 73, 73, 75, 77, 75, 73, 70, 68, 64, 63]   \n",
       "\n",
       "                                       Dewpoint (F)  \\\n",
       "0  [75, 75, 76, 76, 76, 76, 76, 76, 75, 77, 77, 77]   \n",
       "1  [72, 73, 73, 73, 73, 75, 75, 75, 75, 75, 77, 77]   \n",
       "2    [22, 8, 12, 19, 20, 18, 16, 13, 7, 41, 38, 22]   \n",
       "3  [55, 54, 55, 54, 55, 55, 52, 54, 54, 54, 54, 54]   \n",
       "4  [59, 59, 59, 59, 59, 59, 57, 55, 55, 54, 52, 52]   \n",
       "\n",
       "                                       Humidity (%)  \\\n",
       "0  [85, 86, 86, 88, 90, 90, 94, 89, 74, 62, 55, 53]   \n",
       "1  [78, 79, 79, 74, 70, 70, 66, 62, 59, 56, 56, 53]   \n",
       "2  [74, 79, 84, 79, 74, 79, 83, 83, 83, 94, 94, 89]   \n",
       "3  [47, 39, 37, 31, 31, 31, 31, 31, 35, 39, 42, 47]   \n",
       "4  [64, 61, 61, 57, 57, 54, 53, 53, 60, 60, 64, 68]   \n",
       "\n",
       "                                   Wind Speed (mph)  \\\n",
       "0              [2, 3, 3, 3, 4, 4, 2, 4, 2, 4, 6, 6]   \n",
       "1              [5, 6, 2, 5, 7, 5, 5, 7, 5, 6, 5, 2]   \n",
       "2  [18, 18, 20, 21, 20, 20, 20, 20, 17, 10, 11, 11]   \n",
       "3      [3, 6, 8, 12, 13, 15, 16, 18, 15, 15, 13, 9]   \n",
       "4  [13, 17, 18, 17, 21, 23, 21, 23, 18, 20, 17, 15]   \n",
       "\n",
       "                                       Pressure (in)  \\\n",
       "0  [29.8, 29.83, 29.83, 29.86, 29.86, 29.8, 29.83...   \n",
       "1  [29.64, 29.64, 29.64, 29.64, 29.67, 29.67, 29....   \n",
       "2  [30.09, 30.09, 30.06, 30.06, 30.06, 30.06, 30....   \n",
       "3  [28.31, 28.31, 28.28, 28.25, 28.25, 28.22, 28....   \n",
       "4  [29.87, 29.84, 29.84, 29.84, 29.81, 29.81, 29....   \n",
       "\n",
       "                     Percipitation (in)  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                           Condition  Type Of Location Y-Value  \n",
       "0  [Fair, Fair, Partly Cloudy, Fair, Fair, Partly...         Mounatins    Fire  \n",
       "1  [Fair, Fair, Fair, Fair, Windy, Windy, Windy, ...     Coastal Hills    Fire  \n",
       "2  [Fair, Partly Cloudy, Mostly Cloudy, Fair, Par...         Mountains    Fire  \n",
       "3  [Fair, Fair, Fair, Fair, Fair, Fair, Fair, Fai...  Coastal Mountain    Fire  \n",
       "4  [Fair, Fair, Fair, Fair, Windy, Windy, Windy, ...   Costal Mountain    Fire  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_labels = [\"Season Started\", \"Locations Affected\", \"Condition\", \"Type Of Location\", \"Y-Value\"]\n",
    "categorical_scalar_column_labels = [\"Season Started\", \"Locations Affected\", \"Type Of Location\", \"Y-Value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summer    135\n",
      "Spring     75\n",
      "Fall       49\n",
      "Winter     46\n",
      "Name: Season Started, dtype: int64\n",
      "\n",
      "California     23\n",
      "MB             19\n",
      "BC             19\n",
      "AB             18\n",
      "Yellowknife    12\n",
      "               ..\n",
      "MA              1\n",
      "IL              1\n",
      "DC              1\n",
      "Luxembourg      1\n",
      "Hailey          1\n",
      "Name: Locations Affected, Length: 110, dtype: int64\n",
      "\n",
      "Forest               77\n",
      "Mountains            59\n",
      "Hills                16\n",
      "Arctic               11\n",
      "Coastal Forest       10\n",
      "Coastal Mountains    10\n",
      "Flat                  8\n",
      "Rainforest            8\n",
      "Plains                6\n",
      "Grasslands            6\n",
      "Costal Mountain       5\n",
      "Desert                4\n",
      "Swamp                 3\n",
      "Coastal Hills         3\n",
      "Costal Forest         3\n",
      "Coastal Lowland       2\n",
      "Coastal               1\n",
      "Costal Mountains      1\n",
      "Coastal Mountain      1\n",
      "Mounatins             1\n",
      "Name: Type Of Location, dtype: int64\n",
      "\n",
      "Fire        155\n",
      "No Fire      93\n",
      "Not Fire     57\n",
      "Name: Y-Value, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cl in categorical_scalar_column_labels:\n",
    "    print(df[cl].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_columns = df[vector_column_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying all are ndarray\n",
    "# is_ndarray = vector_columns.map(lambda x: isinstance(x, np.ndarray))\n",
    "# is_ndarray.all().all()\n",
    "is_ndarray = vector_columns.applymap(lambda x: isinstance(x, np.ndarray))\n",
    "is_ndarray.all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_shape = (12,)\n",
    "\n",
    "# shape = vector_columns.map(lambda x: x.shape)\n",
    "# # shape == desired_shape  # INVALID SYNTAX\n",
    "# is_desired_shape = shape.map(lambda x: x == desired_shape)\n",
    "\n",
    "shape = vector_columns.applymap(lambda x: x.shape)\n",
    "# shape == desired_shape  # INVALID SYNTAX\n",
    "is_desired_shape = shape.applymap(lambda x: x == desired_shape)\n",
    "\n",
    "# Shorter version\n",
    "#is_desired_shape = vector_columns.map(lambda x: x.shape == desired_shape)\n",
    "is_desired_shape = vector_columns.applymap(lambda x: x.shape == desired_shape)\n",
    "\n",
    "# Boolean series containing whether all vectors in that row are of the desired shape\n",
    "valid_shape_rows = is_desired_shape.all(axis=1)\n",
    "\n",
    "# Whether all vectors are of desired shape\n",
    "is_desired_shape.all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate minimum, average, and maximum values for specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percipitation (in)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Percipitation (in)\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "7  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "9  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to generate stats for\n",
    "columns_to_process = numerical_vector_column_labels\n",
    "\n",
    "# Function to compute min, avg, and max and return as a Series\n",
    "def compute_stats(arr):\n",
    "    return pd.Series([np.min(arr), np.mean(arr), np.max(arr)], index=['min', 'avg', 'max'])\n",
    "\n",
    "# New DataFrame to store results\n",
    "num_stats_df = pd.DataFrame()\n",
    "array_stats_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over specified columns\n",
    "for col in df.columns:\n",
    "    # If the column contains numpy arrays and is in the columns to process\n",
    "    if col in columns_to_process:  # and np.issubdtype(df[col].dtype, np.ndarray)\n",
    "        # Compute statistics for each numpy array element in the column\n",
    "        stats = df[col].apply(compute_stats)\n",
    "        # Rename columns to include the statistics\n",
    "        stats.columns = [f\"{col}_min\", f\"{col}_avg\", f\"{col}_max\"]\n",
    "        # Concatenate the statistics columns with the original column and insert them into the new DataFrame\n",
    "        #num_stats_df = pd.concat([num_stats_df, df[col], stats], axis=1)\n",
    "        array_stats_df = pd.concat([df[col]], axis=1)\n",
    "        num_stats_df = pd.concat([num_stats_df, stats], axis=1)\n",
    "    else:\n",
    "        # If not a numpy array column or not in columns to process, copy it to the new DataFrame\n",
    "        num_stats_df[col] = df[col]\n",
    "\n",
    "num_stats_df.head(10)\n",
    "array_stats_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking element values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Only select for columns where we care if values are missing (do not care if we are missing Fire Name)\n",
    "isna = df.loc[:, \"Year\":\"Y-Value\"].isna()\n",
    "isna.sum()[isna.any()]\n",
    "print(df.isna().sum())\n",
    "\n",
    "# print(df['Type Of Location'].dtype)\n",
    "# df = df.fillna('NaaN')\n",
    "# df.drop(df[df['Type Of Location'] == 'NaaN'].index, inplace = True)\n",
    "# print(df['Type Of Location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking contents for numpy arrays (numerical only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "not df[numerical_vector_column_labels].map(lambda x: np.any(np.isnan(x))).any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "unencoded_df = df.copy(deep=True)\n",
    "\n",
    "mapping_dict = {'BC': 'British Columbia', 'YT': 'Yukon', 'QC': 'Quebec', 'AB': 'Alberta', 'MB': 'Manitoba', 'ON': 'Ontario', 'CA': 'California'}\n",
    "def pain(x) -> str:\n",
    "    # create a temporary list to hold the replaced strings\n",
    "    temp = []\n",
    "    for word in str(x).split():\n",
    "        temp.append(mapping_dict.get(word, word))\n",
    "     \n",
    "    # join the temporary list to create the final output string\n",
    "    res = \" \".join(temp)\n",
    "    # print(temp, res)\n",
    "    return str(res)\n",
    "\n",
    "# Columns containing single categorical values\n",
    "for cl in categorical_scalar_column_labels:\n",
    "    if cl == 'Locations Affected':\n",
    "        # print(unencoded_df['Locations Affected'].value_counts())\n",
    "        df[cl] = df[cl].apply(pain)\n",
    "        pass\n",
    "    df[cl] = le.fit_transform(df[cl])\n",
    "\n",
    "print(df['Condition'])\n",
    "\n",
    "# Columns containing categorical vector values\n",
    "for cl in categorical_vector_column_labels:\n",
    "    le.fit(np.concatenate(df['Condition'].values))\n",
    "    # le.fit_transform(df['Condition'])\n",
    "    df[cl] = df[cl].apply(le.transform)\n",
    "# print(df['Y-Value'].value_counts())\n",
    "print(unencoded_df['Y-Value'].value_counts())\n",
    "print(unencoded_df['Locations Affected'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning a data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Replace y value\n",
    "with pd.option_context('future.no_silent_downcasting', True):\n",
    "    fire_map = {'Fire': 1, 'Fire\\r\\n': 1, 'No Fire': 0, 'Not Fire': 0}\n",
    "    coded_df = pd.DataFrame()\n",
    "    coded_df['Y-Value_encoded'] = unencoded_df['Y-Value'].replace(fire_map).astype(int)\n",
    "    coded_df['Y-Value_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Replace seasons\n",
    "# a = unencoded_df['Season Started'].unique()\n",
    "# replace_dict = {k:v for v, k in enumerate(a)}\n",
    "# print(replace_dict)\n",
    "# coded_df['Season Started_enc'] = unencoded_df['Season Started'].replace(replace_dict)\n",
    "coded_df['Season Started_enc'] = df['Season Started']\n",
    "coded_df['Season Started_enc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Locations Affected\n",
    "# print(df['Locations Affected'].value_counts())\n",
    "b = df['Locations Affected'].unique()\n",
    "print(len(b))\n",
    "# replace_dict = {k:v for v, k in enumerate(b)}\n",
    "# print(replace_dict)\n",
    "# coded_df['Locations Affected_enc'] = unencoded_df['Locations Affected'].replace(replace_dict)\n",
    "coded_df['Locations Affected_enc'] = df['Locations Affected']\n",
    "coded_df['Locations Affected_enc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "coded_df['Type Of Location_enc'] = df['Type Of Location']\n",
    "coded_df['Type Of Location_enc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def str_to_list(x):\n",
    "    test = ''\n",
    "    if type(x) == type(test):\n",
    "        values = x.replace(',','').replace('[','').replace(']','').split(' ')\n",
    "        values = list(filter(None, values))\n",
    "    else:\n",
    "        values = x\n",
    "    # Remove empty strings\n",
    "    l = [float(val) for val in values]\n",
    "    return l\n",
    "\n",
    "def arr_to_intlist(x):\n",
    "    l = [int(val) for val in x]\n",
    "    return l\n",
    "\n",
    "list_columns = numerical_vector_column_labels\n",
    "\n",
    "added_cols = []\n",
    "\n",
    "# First split numerical columns\n",
    "for col in list_columns:\n",
    "    if (df[col].dtype == 'object'):\n",
    "        df[col] = df[col].apply(str_to_list if col != 'Condition' else arr_to_intlist)\n",
    "    \n",
    "    new_columns = [col + str(x) for x in range(12)]\n",
    "    added_cols = added_cols + new_columns\n",
    "    coded_df[new_columns] = pd.DataFrame(df[col].tolist(), columns=new_columns)\n",
    "    print(coded_df[new_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_var = 'Y-Value_encoded'\n",
    "feature_var = ['Season Started_enc', 'Locations Affected_enc', 'Type Of Location_enc'] + added_cols\n",
    "X_train, X_test, y_train, y_test = train_test_split(coded_df[feature_var], coded_df[target_var], test_size=0.2, shuffle=True, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "repeatkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=6969)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print('CV accuracy scores are', cross_val_score(model, X_train, y_train, scoring='accuracy', cv= kfold, n_jobs=-1))\n",
    "\n",
    "print('The average KFold scores is', np.mean(cross_val_score(model, X_train, y_train, scoring='accuracy', cv=kfold, n_jobs=-1)))\n",
    "print('The average LOOCV score is', np.mean(cross_val_score(model, X_train, y_train, scoring='accuracy', cv=loo, n_jobs=-1)))\n",
    "print('The average RepeatedKFold score is', np.mean(cross_val_score(model, X_train, y_train, cv=repeatkf, n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Set parameter to be searched in a range\n",
    "params = {'n_neighbors': range(1,150)}\n",
    "\n",
    "# Initiate the KNN model and GridSearchCV function\n",
    "knn = KNeighborsClassifier()\n",
    "grid_knn = GridSearchCV(estimator=knn, param_grid=params,\n",
    "                        scoring='accuracy', cv=5)\n",
    "\n",
    "# Fit the function to train set \n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# Find the best parameter and see how well it performs on test set\n",
    "print(grid_knn.best_params_)\n",
    "print(grid_knn.score(X_test, y_test))\n",
    "print(grid_knn.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = []\n",
    "n_iterations = 1000\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    X_sparse, y_sparse = resample(X_test, y_test, replace=True)\n",
    "    predict = model.predict(X_sparse)\n",
    "    score = accuracy_score(y_sparse, predict)\n",
    "    accuracy.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Find median\n",
    "median = np.median(accuracy)\n",
    "\n",
    "# Find lower and upper bounds\n",
    "lower = np.percentile(accuracy, 2.5)\n",
    "upper = np.percentile(accuracy, 97.5)\n",
    "\n",
    "print(f'The median is {median:.2f} '\n",
    "      f'with confidence intervals of [{lower:.2f}, {upper:.2f}].')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/opt/python@3/libexec/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/opt/python@3/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.kdeplot(accuracy)\n",
    "plt.title('1000 Bootstrap Samples of Test Set')\n",
    "plt.xlabel('Accuracy of GaussianNB')\n",
    "plt.axvline(median, 0, 16, linestyle=\"--\")\n",
    "plt.axvline(lower, 0, 16, linestyle=\"--\", color=\"red\")\n",
    "plt.axvline(upper, 0, 16, linestyle=\"--\", color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
